{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "finetuning.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "jYh0ZTeo2l7c"
      },
      "source": [
        "from torch import nn, optim, as_tensor\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import lr_scheduler\n",
        "from torch.nn.init import *\n",
        "from torchvision import transforms, utils, datasets, models\n",
        "from facenet_pytorch import MTCNN, InceptionResnetV1\n",
        "import cv2\n",
        "from PIL import Image\n",
        "from pdb import set_trace\n",
        "import time\n",
        "import copy\n",
        "from pathlib import Path\n",
        "import os\n",
        "import sys\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.animation as animation\n",
        "from skimage import io, transform\n",
        "from tqdm import trange, tqdm\n",
        "import csv\n",
        "import glob\n",
        "import dlib\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BBC_UwXpKWIw"
      },
      "source": [
        "!pip install facenet-pytorch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T8EUQgCU3Ehn"
      },
      "source": [
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        #transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    'val': transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "}\n",
        "\n",
        "image_datasets = {x: datasets.CelebA(root='celebA_data/', split=x, target_type='identity', download=True,transform=data_transforms[x]) for x in ['train', 'val']}\n",
        "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=8, shuffle=True) for x in ['train', 'val']}\n",
        "dataset_sizes = {x: len(image_datasets[x]) for x in ['train','val']}\n",
        "class_names = image_datasets['train'].classes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vpq5e__QCwqx"
      },
      "source": [
        "model_ft = InceptionResnetV1(pretrained='vggface2', classify=False, num_classes = len(class_names))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pd0rF4s-KElc"
      },
      "source": [
        "model_ft = nn.Sequential(*list(model_ft.children())[:-4])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1mj0S9_ahVD2"
      },
      "source": [
        "for param in model_ft.parameters():\n",
        "    param.requires_grad = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3XpdG8wCilSc"
      },
      "source": [
        "model_ft.last_linear = nn.Sequential(\n",
        "    Flatten(),\n",
        "    nn.Linear(in_features=1792, out_features=320, bias=False),\n",
        "    normalize()\n",
        ")\n",
        "model_ft.logits = nn.Linear(layer_list[3].in_features, len(class_names))\n",
        "model_ft.softmax = nn.Softmax(dim=1)\n",
        "model_ft = model_ft.to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer_ft = optim.SGD(model_ft.parameters(), lr=1e-2, momentum=0.9)\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\n",
        "num_epochs=25"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nmjRi5eIiy0J"
      },
      "source": [
        "since = time.time()\n",
        "FT_losses = []\n",
        "best_model_wts = copy.deepcopy(model_ft.state_dict())\n",
        "best_acc = 0.0\n",
        "for epoch in range(num_epochs):\n",
        "    print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "    print('-' * 10)\n",
        "    for phase in ['train', 'val']:\n",
        "        if phase == 'train':\n",
        "            model_ft.train()  \n",
        "        else:\n",
        "            model_ft.eval()  \n",
        "        running_loss = 0.0\n",
        "        running_corrects = 0\n",
        "        # Iterate over data.\n",
        "        for inputs, labels in dataloaders[phase]:\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "            optimizer_ft.zero_grad()\n",
        "            with torch.set_grad_enabled(phase == 'train'):\n",
        "                outputs = model_ft(inputs)\n",
        "                _, preds = torch.max(outputs, 1)\n",
        "                loss = criterion(outputs, labels)\n",
        "                if phase == 'train':\n",
        "                    loss.backward()\n",
        "                    optimizer_ft.step()\n",
        "                    scheduler.step()\n",
        "            FT_losses.append(loss.item())\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "            running_corrects += torch.sum(preds == labels.data)\n",
        "        epoch_loss = running_loss / dataset_sizes[phase]\n",
        "        epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
        "        print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
        "        if phase == 'val' and epoch_acc > best_acc:\n",
        "            best_acc = epoch_acc\n",
        "            best_model_wts = copy.deepcopy(model_ft.state_dict())\n",
        "time_elapsed = time.time() - since\n",
        "print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
        "print('Best val Acc: {:4f}'.format(best_acc))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}